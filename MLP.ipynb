{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adult', 'Airplane', 'Alpaca', 'Bird', 'Bus', 'Car', 'Cat', 'Child', 'Elephant', 'Flower', 'Giraffe', 'Horse', 'Monkey', 'Panda', 'Reptile', 'Vessel']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "classes = os.listdir('final_dataset/train')\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "\n",
    "for item in classes:\n",
    "    all_items = os.listdir('final_dataset/train'+'/'+item)\n",
    "    for itemm in all_items:\n",
    "        items.append((item, str('final_dataset/train'+'/'+item)+'/'+itemm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  item class                                         image\n",
      "0      Adult     final_dataset/train/Adult/adults_ (1).jpg\n",
      "1      Adult    final_dataset/train/Adult/adults_ (10).jpg\n",
      "2      Adult  final_dataset/train/Adult/adults_ (100).JPEG\n",
      "3      Adult  final_dataset/train/Adult/adults_ (101).JPEG\n",
      "4      Adult  final_dataset/train/Adult/adults_ (102).JPEG\n",
      "     item class                                         image\n",
      "1833     Vessel  final_dataset/train/Vessel/vessels_ (95).jpg\n",
      "1834     Vessel  final_dataset/train/Vessel/vessels_ (96).jpg\n",
      "1835     Vessel  final_dataset/train/Vessel/vessels_ (97).jpg\n",
      "1836     Vessel  final_dataset/train/Vessel/vessels_ (98).jpg\n",
      "1837     Vessel  final_dataset/train/Vessel/vessels_ (99).jpg\n"
     ]
    }
   ],
   "source": [
    "items_df = pd.DataFrame(data = items, columns =['item class','image'])\n",
    "print(items_df.head())\n",
    "print(items_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "path = 'final_dataset/train'\n",
    "\n",
    "\n",
    "im_size= 300\n",
    "\n",
    "images=[]\n",
    "labels=[]\n",
    "\n",
    "for i in classes:\n",
    "    data_path =  path + '/'+str(i)\n",
    "    filenames=[i for i in os.listdir(data_path)]\n",
    "    \n",
    "    for f in filenames:\n",
    "        img=cv2.imread(data_path+'/'+f)\n",
    "        img =cv2.resize(img, (im_size,im_size))\n",
    "        images.append(img)\n",
    "        labels.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1838, 300, 300, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = np.array(images)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype('float32')/255.0 #pixel intensity lies between 0 to 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1838, 300, 300, 3)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adult' 'Adult' 'Adult' ... 'Vessel' 'Vessel' 'Vessel']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "y=items_df['item class'].values\n",
    "print(y[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ... 15 15 15]\n"
     ]
    }
   ],
   "source": [
    "y_labelencoder = LabelEncoder()\n",
    "y=y_labelencoder.fit_transform(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1470, 300, 300, 3)\n",
      "(368, 300, 300, 3)\n",
      "(1470,)\n",
      "(368,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images, y = shuffle(images,y, random_state=1)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(images, y, test_size=0.2)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 270000)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               69120256  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                4112      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,124,368\n",
      "Trainable params: 69,124,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(300,300,3)),\n",
    "    keras.layers.Dense(256, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(16, activation=tf.nn.softmax)\n",
    "])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 42s 876ms/step - loss: 5.3813 - accuracy: 0.0551\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 40s 863ms/step - loss: 2.8771 - accuracy: 0.0769\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 39s 848ms/step - loss: 2.8071 - accuracy: 0.0646\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 42s 915ms/step - loss: 2.7966 - accuracy: 0.0585\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 42s 904ms/step - loss: 2.8010 - accuracy: 0.0633\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 42s 902ms/step - loss: 2.8024 - accuracy: 0.0476\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 41s 891ms/step - loss: 2.8004 - accuracy: 0.0701\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 41s 886ms/step - loss: 2.7994 - accuracy: 0.0626\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 41s 888ms/step - loss: 2.8031 - accuracy: 0.0585\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 42s 904ms/step - loss: 2.8117 - accuracy: 0.0517\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 41s 900ms/step - loss: 2.8062 - accuracy: 0.0619\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 42s 905ms/step - loss: 2.8092 - accuracy: 0.0673\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 42s 902ms/step - loss: 2.8002 - accuracy: 0.0776\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 41s 890ms/step - loss: 2.8041 - accuracy: 0.0660\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 41s 893ms/step - loss: 2.8126 - accuracy: 0.0612\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 41s 891ms/step - loss: 2.8118 - accuracy: 0.0531\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 42s 908ms/step - loss: 2.8033 - accuracy: 0.0592\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 41s 889ms/step - loss: 2.8005 - accuracy: 0.0592\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 41s 887ms/step - loss: 2.7975 - accuracy: 0.0673\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 41s 900ms/step - loss: 2.8055 - accuracy: 0.0660\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 42s 912ms/step - loss: 2.8171 - accuracy: 0.0483\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 41s 899ms/step - loss: 2.8104 - accuracy: 0.0633\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 41s 888ms/step - loss: 2.8091 - accuracy: 0.0667\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 42s 908ms/step - loss: 2.8217 - accuracy: 0.0571\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 41s 901ms/step - loss: 2.8079 - accuracy: 0.0667\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 42s 904ms/step - loss: 2.7986 - accuracy: 0.0626\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 42s 907ms/step - loss: 2.8092 - accuracy: 0.0585\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 42s 904ms/step - loss: 2.8074 - accuracy: 0.0612\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 41s 888ms/step - loss: 2.8123 - accuracy: 0.0646\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 41s 896ms/step - loss: 2.8119 - accuracy: 0.0626\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 41s 889ms/step - loss: 2.7992 - accuracy: 0.0639\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 39s 845ms/step - loss: 2.8032 - accuracy: 0.0653\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 40s 860ms/step - loss: 2.7951 - accuracy: 0.0680\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 42s 908ms/step - loss: 2.8033 - accuracy: 0.0646\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 42s 923ms/step - loss: 2.8162 - accuracy: 0.0592\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 42s 903ms/step - loss: 2.8065 - accuracy: 0.0680\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 43s 942ms/step - loss: 2.8184 - accuracy: 0.0735\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 40s 860ms/step - loss: 2.8102 - accuracy: 0.0619\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 40s 874ms/step - loss: 2.8056 - accuracy: 0.0578\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 42s 901ms/step - loss: 2.8099 - accuracy: 0.0578\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 39s 856ms/step - loss: 2.8004 - accuracy: 0.0578\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 40s 869ms/step - loss: 2.8094 - accuracy: 0.0755\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 40s 870ms/step - loss: 2.8000 - accuracy: 0.0660\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 42s 919ms/step - loss: 2.8077 - accuracy: 0.0707\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 46s 1s/step - loss: 2.8135 - accuracy: 0.0687\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 42s 912ms/step - loss: 2.8111 - accuracy: 0.0687\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 43s 933ms/step - loss: 2.8161 - accuracy: 0.0558\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 44s 957ms/step - loss: 2.8048 - accuracy: 0.0605\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 41s 898ms/step - loss: 2.8085 - accuracy: 0.0639\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 41s 902ms/step - loss: 2.8086 - accuracy: 0.0612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15b134c6910>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 82ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.05926634, 0.04852723, 0.09281002, ..., 0.07718588, 0.03549857,\n",
       "        0.0373262 ],\n",
       "       [0.05926634, 0.04852723, 0.09281002, ..., 0.07718588, 0.03549857,\n",
       "        0.0373262 ],\n",
       "       [0.05926634, 0.04852723, 0.09281002, ..., 0.07718588, 0.03549857,\n",
       "        0.0373262 ],\n",
       "       ...,\n",
       "       [0.05926634, 0.04852723, 0.09281002, ..., 0.07718588, 0.03549857,\n",
       "        0.0373262 ],\n",
       "       [0.05926634, 0.04852723, 0.09281002, ..., 0.07718588, 0.03549857,\n",
       "        0.0373262 ],\n",
       "       [0.05926634, 0.04852723, 0.09281002, ..., 0.07718588, 0.03549857,\n",
       "        0.0373262 ]], dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(test_x)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m----> 2\u001b[0m confusion_matrix(test_y, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\shoba\\ML\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:317\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfusion_matrix\u001b[39m(\n\u001b[0;32m    233\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    234\u001b[0m ):\n\u001b[0;32m    235\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \n\u001b[0;32m    237\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    318\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    319\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\shoba\\ML\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     97\u001b[0m             type_true, type_pred\n\u001b[0;32m     98\u001b[0m         )\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 270000)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               69120256  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,137,744\n",
      "Trainable params: 69,137,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(300,300,3)),\n",
    "    keras.layers.Dense(256, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(16, activation=tf.nn.softmax)\n",
    "])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 52s 976ms/step - loss: 2.9139 - accuracy: 0.0612\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 42s 923ms/step - loss: 2.8087 - accuracy: 0.0646\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 42s 920ms/step - loss: 2.8013 - accuracy: 0.0735\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 42s 915ms/step - loss: 2.8155 - accuracy: 0.0585\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 42s 911ms/step - loss: 2.7962 - accuracy: 0.0769\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 44s 949ms/step - loss: 2.7913 - accuracy: 0.0714\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 43s 937ms/step - loss: 2.7884 - accuracy: 0.0728\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 41s 881ms/step - loss: 2.7966 - accuracy: 0.0755\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 41s 897ms/step - loss: 2.7857 - accuracy: 0.0864\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 40s 867ms/step - loss: 2.7867 - accuracy: 0.0680\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 42s 918ms/step - loss: 2.7837 - accuracy: 0.0782\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 47s 1s/step - loss: 2.7880 - accuracy: 0.0639\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 46s 1s/step - loss: 2.7809 - accuracy: 0.0762\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 44s 960ms/step - loss: 2.7959 - accuracy: 0.0673\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 38s 825ms/step - loss: 2.7811 - accuracy: 0.0687\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 37s 807ms/step - loss: 2.7781 - accuracy: 0.0728\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 39s 846ms/step - loss: 2.7800 - accuracy: 0.0701\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 40s 863ms/step - loss: 2.7780 - accuracy: 0.0844\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 41s 896ms/step - loss: 2.7804 - accuracy: 0.0721\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 41s 886ms/step - loss: 2.7790 - accuracy: 0.0755\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 39s 838ms/step - loss: 2.7751 - accuracy: 0.0701\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 39s 837ms/step - loss: 2.7730 - accuracy: 0.0776\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 37s 809ms/step - loss: 2.7719 - accuracy: 0.0721\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 40s 868ms/step - loss: 2.7707 - accuracy: 0.0782\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 41s 898ms/step - loss: 2.7700 - accuracy: 0.0782\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 40s 860ms/step - loss: 2.7694 - accuracy: 0.0728\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 38s 817ms/step - loss: 2.7688 - accuracy: 0.0687\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 38s 820ms/step - loss: 2.7683 - accuracy: 0.0816\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 39s 846ms/step - loss: 2.7684 - accuracy: 0.0823\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 40s 878ms/step - loss: 2.7677 - accuracy: 0.0816\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 41s 892ms/step - loss: 2.7673 - accuracy: 0.0816\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 40s 869ms/step - loss: 2.7670 - accuracy: 0.0816\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 37s 812ms/step - loss: 2.7668 - accuracy: 0.0816\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 46s 995ms/step - loss: 2.7666 - accuracy: 0.0816\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 41s 882ms/step - loss: 2.7664 - accuracy: 0.0816\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 42s 905ms/step - loss: 2.7662 - accuracy: 0.0816\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 42s 924ms/step - loss: 2.7661 - accuracy: 0.0816\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 41s 882ms/step - loss: 2.7661 - accuracy: 0.0816\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 39s 857ms/step - loss: 2.7659 - accuracy: 0.0816\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 42s 914ms/step - loss: 2.7658 - accuracy: 0.0816\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 47s 1s/step - loss: 2.7656 - accuracy: 0.0816\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 49s 1s/step - loss: 2.7656 - accuracy: 0.0816\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 48s 1s/step - loss: 2.7656 - accuracy: 0.0816\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 43s 938ms/step - loss: 2.7656 - accuracy: 0.0816\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 39s 844ms/step - loss: 2.7654 - accuracy: 0.0816\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 41s 884ms/step - loss: 2.7654 - accuracy: 0.0816\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 42s 919ms/step - loss: 2.7653 - accuracy: 0.0816\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 46s 987ms/step - loss: 2.7654 - accuracy: 0.0816\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 42s 921ms/step - loss: 2.7654 - accuracy: 0.0816\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 41s 884ms/step - loss: 2.7654 - accuracy: 0.0816\n",
      "12/12 [==============================] - 1s 60ms/step\n"
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer=tf.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.fit(train_x, train_y, epochs=50)\n",
    "\n",
    "\n",
    "y_pred2=model2.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\shoba\\ML\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\shoba\\ML\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\shoba\\ML\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\shoba\\ML\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\shoba\\ML\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\shoba\\ML\\env\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 300, 300, 3), found shape=(None, 300, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m imgt\u001b[39m=\u001b[39mimgt\u001b[39m.\u001b[39mreshape((\u001b[39m300\u001b[39m,\u001b[39m300\u001b[39m,\u001b[39m3\u001b[39m))\n\u001b[0;32m      5\u001b[0m sample \u001b[39m=\u001b[39m test_x[\u001b[39m1\u001b[39m] \n\u001b[1;32m----> 6\u001b[0m model2\u001b[39m.\u001b[39;49mpredict(imgt)\n",
      "File \u001b[1;32mc:\\Users\\shoba\\ML\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileh2eo16qd.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\shoba\\ML\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\shoba\\ML\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\shoba\\ML\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\shoba\\ML\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\shoba\\ML\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\shoba\\ML\\env\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 300, 300, 3), found shape=(None, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "rand = np.random.RandomState(42)\n",
    "imgt=cv2.imread('image/aadult.jpg')\n",
    "imgt =cv2.resize(imgt, (im_size,im_size))\n",
    "imgt=imgt.reshape((300,300,3))\n",
    "sample = test_x[1] \n",
    "model2.predict(imgt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
